# -*- coding: utf-8 -*-
"""Expenses_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXooYEx9fSqLfML7nXOv_8lpCHnyYTFO
"""

import pandas as pd
import re


# Functions
def refactor_cols(my_df):
    columns = list(my_df.columns)
    columns = [c.lower() for c in columns]
    columns = [c.replace(' ', '_') for c in columns]
    my_df.columns = columns
    my_df.drop(columns='status', inplace=True)
    my_df["date"] = pd.to_datetime(my_df["date"])

    return my_df


def extract_patterns():
    patterns_df = pd.read_csv("./bank_regexes.csv")
    patterns_dict = patterns_df.to_dict()

    global split_patterns
    split_patterns = [r'\d{3}-\d{3}.*\d{4}',
                      r'.com',
                      r'\*+',
                      r'\W+\s+co',
                      r'#+']
    # split_patterns = [v for k, v in patterns_dict['split'].items()]

    global search_patterns
    search_patterns = [re.compile(r'7.*eleven'),
                       re.compile(r'target'),
                       re.compile(r'amc'),
                       re.compile(r'build-a-bear'),
                       re.compile(r'party\s+city'),
                       re.compile(r'jimmy\s+johns'),
                       re.compile(r'uchealth'),
                       re.compile(r'netflix'),
                       re.compile(r'amazon'),
                       re.compile(r'amzn'),
                       re.compile(r'adobe'),
                       re.compile(r'zappos'),
                       re.compile(r'panda\s+express'),
                       re.compile(r'prime\s+video'),
                       re.compile(r'king soop'),
                       re.compile(r'nintendo'),
                       re.compile(r'apple'),
                       re.compile(r'starbucks'),
                       re.compile(r'wal.*mart'),
                       re.compile(r'taco\s+bell'),
                       re.compile(r'doordash')]
    # search_patterns = [v for k, v in patterns_dict['search'].items()]


def sum_col(raw_df, my_col):
    drop_cols = [c for c in raw_df.columns if c not in ['amount', my_col]]

    my_df = raw_df.copy(deep=True)
    my_df.drop(columns=drop_cols, inplace=True)

    my_df[my_col] = my_df[my_col].apply(lambda x: x.lower())

    for patt1 in split_patterns:
        my_df[my_col] = my_df[my_col].apply(lambda x: re.split(patt1, x)[0] if re.split(patt1, x) else x)

    for patt2 in search_patterns:
        my_df[my_col] = my_df[my_col].apply(lambda x: re.search(patt2, x).group(0) if re.search(patt2, x) else x)

    my_df = my_df.groupby(my_col).agg('sum')
    my_df.sort_values(by=[my_col], inplace=True)
    my_df.reset_index(inplace=True)

    return my_df


def main():
    # Get regexes for column string transformations
    extract_patterns()

    # Debit Card Analysis
    debit_df = pd.read_csv("./debit_transactions_Jan-Aug_2023.csv")
    debit_df = refactor_cols(debit_df)

    debit_category_df = sum_col(debit_df, 'category')
    debit_category_df.to_csv('./debit_category_totals.csv')

    debit_desc_df = sum_col(debit_df, 'description')
    debit_desc_df.to_csv('./debit_description_totals.dsv')

    debit_orig_desc_df = sum_col(debit_df, 'original_description')
    debit_orig_desc_df.to_csv('./debit_original_description_totals.csv')

    # Credit Card Analysis
    cc_df = pd.read_csv("./cc_transactions_Jan-Aug_2023.csv")
    cc_df = refactor_cols(cc_df)

    cc_cat_df = sum_col(cc_df, 'category')
    cc_cat_df.to_csv('./cc_category_totals.csv')

    cc_desc_df = sum_col(cc_df, 'description')
    cc_desc_df.to_csv('./cc_description_totals.csv')

    cc_orig_desc_df = sum_col(cc_df, 'original_description')
    cc_orig_desc_df.to_csv('./cc_original_descriptions.csv')

    print(debit_orig_desc_df)


if __name__ == '__main__':
    main()
